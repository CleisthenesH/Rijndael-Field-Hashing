% Copyright 2023 Kieran W Harvie. All rights reserved.

\chapter{Matrix Methods}
From an abstract algebra a matrix is actually a type of tensor as field[
it the underlying object is just a ring it's called a module.
Say how walking through a $3\times 3$ examples is useful to show only field operations is used.
set spell not working?

MAKE SURE TO USE THE APPENDIX!!

\section{Gaussian Elimination}
\subsection{(pointlessly) Abstract Algebra Preamble}
From an abstract algebra viewpoint,
the choice of dual space basis is arbitrary provided they have the right span.
We can get such a new dual basis $\mathbf{e'_i}$ from an old basis $\mathbf{e_j}$, provided $T$ is non-singular, through:
\[\mathbf{e'_i} = T(\{\mathbf{e_j}\})\]
So we can transform relationship between the coefficients of tensors in one basis it to another,
and if $T$ is affine then the new coefficients are directly transformed through $T$.
\\

Three particular choices of $T$ are swapping two the basis elements,
multiplying a basis element by a non-zero constant,
and adding a multiple of basis element index to another.

\subsection{(useful) Matrix Preamble}
\label{matrix:useful-preamble}
Abstract tensor analysis is cool,
for the type of people that like that type of thing,
but the useful result of the previous subsection is that for matrices $a$, $b$, and $M$, plus an invertible matrix $T$ we have:
\[ M^j_ia^i = b^i \Leftrightarrow\, T^j_kM^k_ia^i = T^j_kb^k \]
(And this result can be verified directly by multiplying by $T$ or $T^{-1}$ and short-circuiting the previous preamble).
\\

Bellow are examples of the three previous particualr choices of $T$,
hence forth referred to as elementary row operations,
for $3\times 3$ matrices:
\begin{equation*}
\begin{aligned}
\begin{bmatrix}
	1&0&0 \\
	0&0&1 \\
	0&1&0 \\
\end{bmatrix}
\begin{bmatrix}
	m_{11} & m_{12} & m_{13} \\
	m_{21} & m_{22} & m_{23} \\
	m_{31} & m_{32} & m_{33} \\
\end{bmatrix}
=&
\begin{bmatrix}
	m_{11} & m_{12} & m_{13} \\
	m_{31} & m_{32} & m_{33} \\
	m_{21} & m_{22} & m_{23} \\
\end{bmatrix} \\
\begin{bmatrix}
	1&0&0 \\
	0&a&0 \\
	0&0&1 \\
\end{bmatrix}
\begin{bmatrix}
	m_{11} & m_{12} & m_{13} \\
	m_{21} & m_{22} & m_{23} \\
	m_{31} & m_{32} & m_{33} \\
\end{bmatrix}
=&
\begin{bmatrix}
	m_{11} & m_{12} & m_{13} \\
	am_{21} & am_{22} & am_{23} \\
	m_{31} & m_{32} & m_{33} \\
\end{bmatrix} \\
\begin{bmatrix}
	1&0&0 \\
	0&1&0 \\
	0&a&1 \\
\end{bmatrix}
\begin{bmatrix}
	m_{11} & m_{12} & m_{13} \\
	m_{21} & m_{22} & m_{23} \\
	m_{31} & m_{32} & m_{33} \\
\end{bmatrix}
=&
\begin{bmatrix}
	m_{11} & m_{12} & m_{13} \\
	m_{21} & m_{22} & m_{23} \\
	m_{31}+am_{21} & m_{32}+am_{22} & m_{33}+am_{23} \\
\end{bmatrix} \\
\end{aligned}
\end{equation*}

Since these elementary row operations can be represented through matrices their composition can be represented through matrix multiplication.
Hence we can build more complex row operations from multiplying a chain of elementary row operations together.
\\

For example say we want a transform $T$ that takes the a $3\times 3$ matrix and makes it first column $[1,0,0]$.
Assuming $m_{1n} \neq 0$, we have:
\begin{equation*}
\begin{aligned}
\begin{bmatrix}
	m_{11}^{-1}&0&0 \\
	0&m_{22}^{-1}&0 \\
	0&0&m_{33}^{-1} \\
\end{bmatrix}
\begin{bmatrix}
	m_{11} & m_{12} & m_{13} \\
	m_{21} & m_{22} & m_{23} \\
	m_{31} & m_{32} & m_{33} \\
\end{bmatrix}
=&
\begin{bmatrix}
	1 & m_{12}m_{11}^{-1} & m_{13}m_{11}^{-1} \\
	1 & m_{22}m_{12}^{-1} & m_{23}m_{12}^{-1} \\
	1 & m_{32} m_{32}^{-1}& m_{33} m_{31}^{-1} \\
\end{bmatrix} \\
\begin{bmatrix}
	1&0&0 \\
	-1&1&0 \\
	-1&0&1 \\
\end{bmatrix}
\begin{bmatrix}
	1 & m_{12}m_{11}^{-1} & m_{13}m_{11}^{-1} \\
	1 & m_{22}m_{12}^{-1} & m_{23}m_{12}^{-1} \\
	1 & m_{32} m_{32}^{-1}& m_{33} m_{31}^{-1} \\
\end{bmatrix} 
=&
\begin{bmatrix}
	1 & m_{12}m_{11}^{-1} & m_{13}m_{11}^{-1} \\
	0 & m_{22}m_{12}^{-1}-m_{12}m_{11}^{-1} & m_{23}m_{12}^{-1} -m_{13}m_{11}^{-1}\\
	0 & m_{32} m_{32}^{-1}-m_{12}m_{11}^{-1}& m_{23} m_{31}^{-1} -m_{13}m_{11}^{-1}\\
\end{bmatrix} \\
\end{aligned}
\end{equation*}
Hence:
\[T =
\begin{bmatrix}
	1&0&0 \\
	-1&1&0 \\
	-1&0&1 \\
\end{bmatrix}
\begin{bmatrix}
	m_{11}^{-1}&0&0 \\
	0&m_{22}^{-1}&0 \\
	0&0&m_{33}^{-1} \\
\end{bmatrix}
\]
\\

Gaussian Elimination is simply using this process to find a matrix $T$ such that $T(M) = I$ by interatvly zeroing the outer, non-diagonal, elments:
\[
\begin{bmatrix}
	m_{11} & m_{12} & m_{13} \\
	m_{21} & m_{22} & m_{23} \\
	m_{31} & m_{32} & m_{33} \\
\end{bmatrix}
\rightarrow
\begin{bmatrix}
	1&0&0\\
	0 & m'_{22} & m'_{23} \\
	0 & m'_{32} & m'_{33} \\
\end{bmatrix}
\rightarrow
\begin{bmatrix}
	1&0&0\\
	0 & 1 & 0 \\
	0 & 0 & m''_{33} \\
\end{bmatrix}
\rightarrow
\begin{bmatrix}
	1&0&0\\
	0 & 1 & 0 \\
	0 & 0 & 1 \\
\end{bmatrix}
\]
This calculates $M^{-1}$ as the product of matrices representing elemetry row operations.
Note that this always works when $M$ is invertable, adafsd 
but we may need to swap row such that errent zeros put directly into their destination to avoid dividing by zero.

Rrwrite to bring in the opening.
Jordan normal form??

\subsection{The Algorithm}
Matrices can easily be represented as 2d-arrays,
elementary row operations aren't hard to implement either,
and the iterative nature of final equation directly suggests the structure of the algorithm.
However there is one more observation 
instead of keeping in memory all the elementary row operation, just directly apply them to the $B$ as we go.
Augmented matrices are excellent at facilitating this.

\section{Application to Hashing}
Consider an array of $n$ strings, $s_i$, and an array of $n$ values, $a_i$.
Let their be some function $f$ that converts a string to $n$ field elements.
Let $m_{i,j}$ be the $j$th field element for string $s_i$.
Construct the matrix $M$ from $m_{i,j}$ and the column vector $A$ from $a_i$ in the unusual ways.
If $M$ is invertible, then we can use the above algorithm obtains a column vector $B$ such that:
\[MB = A\]
Which in element form is:
\[\sum_{k=1}^nb_jf(s_i)_j = a_i\]
Which defines the hash function:
\[h(s)=\sum_{k=1}^nb_jf(s)_j\]
Such that:
\[h(s_i) = a_i\]
As required.

\subsection{Example}
Consider the strings:
\[s_1 = \text{"APPLE"},\quad s_2 = \text{"ORANGE"} \]
The hash values:
\[a_1 = 01,\quad a_2 = 02\]
The expression $f(s_i)_j$ maps the $j$th character in the $i$th string to it's place in the alphabet.
Relevant conversions done bellow,
full conversion can be found in the \hyperref[theory:byte]{theory section}:

\begin{center}
\begin{tabular}{|c|c|c|}
	\hline
	Character & Decimal & Field Element \\	
	\hline
	A &  1 & 01 \\
	O & 15 & 0A \\
	P & 16 & 10 \\
	R & 18 & 12 \\
	\hline
\end{tabular}
\end{center}

Hence the requirement for $B$ is such:
\[ 
\begin{bmatrix}
	01&10\\
	0A&12\\
\end{bmatrix}
\begin{bmatrix}
	b_1 \\ b_2\\
\end{bmatrix}
=
\begin{bmatrix}
	01\\ 02 \\
\end{bmatrix}
\]
Which has solution:
\[
\begin{bmatrix}
	b_1 \\ b_2\\
\end{bmatrix}
=
\begin{bmatrix}
	18\\F8 \\
\end{bmatrix}
\]
And gives the hash function:
\[h(s) = 18\times f(s)_1+F8\times f(s)_2\]

\subsection{Uniqueness}
$Ma_0 = Ma_1$ for invertible $M$

\subsection{Invertibility}
liner and human names
preprocessing/offsetting
